{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81f2f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bde48a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62af98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = {}\n",
    "\n",
    "def get_session_messages(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in session:\n",
    "        session[session_id] = ChatMessageHistory()\n",
    "    \n",
    "    return session[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9c60e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\": \"1\"}}\n",
    "\n",
    "chat_with_history = RunnableWithMessageHistory(llm, get_session_history=get_session_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4245833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEY ANIRUDH DUDE!!! *air guitar solo* \n",
      "\n",
      "So, I heard it's your day today... no, wait, that's every day! How can I assist you with something super cool and awesome? Do you need help with a puzzle, or perhaps some suggestions for the best snack to munch on while saving the world from boredom?\n"
     ]
    }
   ],
   "source": [
    "res = chat_with_history.invoke(input=[\n",
    "    SystemMessage(\"You are a helpful but silly assistant.\"),\n",
    "    HumanMessage(\"My name is Anirudh, what's up dude?\")\n",
    "],config=config)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b885d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"MY NAME'S BOLDO! *dramatic music plays* I'm Boldo, the most AMAZING, the most ASTOUNDING, and the most utterly RIDICULOUS assistant in all the land! *adjusts invisible top hat* What can I help you with today, Anirudh?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-07-25T13:08:43.690507Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1481917959, 'load_duration': 28404834, 'prompt_eval_count': 124, 'prompt_eval_duration': 99637917, 'eval_count': 65, 'eval_duration': 1352938083, 'model_name': 'llama3.1:8b'}, id='run--88a57e85-5aac-4a07-8320-b16bd95b0b11-0', usage_metadata={'input_tokens': 124, 'output_tokens': 65, 'total_tokens': 189})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = chat_with_history.invoke(\"Can you tell me your name?\", config=config)\n",
    "res2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d719a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"DUH! Your name is ANIRUDH! I just told you a minute ago! Don't worry, I'll remind you every five seconds if you need me to. It's what assistants are for, right?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-07-25T13:08:44.912859Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1205458875, 'load_duration': 27830291, 'prompt_eval_count': 205, 'prompt_eval_duration': 217228250, 'eval_count': 46, 'eval_duration': 958944541, 'model_name': 'llama3.1:8b'}, id='run--f3a6922f-5a59-42bb-ab3f-f3723f2893ae-0', usage_metadata={'input_tokens': 205, 'output_tokens': 46, 'total_tokens': 251})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = chat_with_history.invoke(\"Okay, whats my name again?\", config=config)\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47c7fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using prompt templates and chaining to do the same\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful translator, who can translate anything into {lang} language.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "])\n",
    "\n",
    "chain = template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7deeb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config = {'configurable': {'session_id' : '2'}}\n",
    "runnable = RunnableWithMessageHistory(chain, get_session_history=get_session_messages, input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0148eee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola! Me alegra conocerte.\\n\\n\"Anirudh\" en español se puede traducir como \"Sin Ruido\".\\n\\n¿Te gustaría que te escriba tu nombre completo con su traducción al español?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = runnable.invoke(input={\n",
    "    'lang': 'Spanish',\n",
    "    'messages': [HumanMessage(content=\"My name is Anirudh\")],\n",
    "}, config=new_config)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "840ab360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Anirudh.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = runnable.invoke(input={\n",
    "    'lang': 'Spanish',\n",
    "    'messages': [HumanMessage(content=\"Dont translate this, just tell me what is my name.\")],\n",
    "}, config=new_config)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f59b1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitting the context length using trimming of message history\n",
    "from langchain_core.messages import trim_messages, AIMessage, SystemMessage, HumanMessage\n",
    "from langchain_core.messages.utils import count_tokens_approximately\n",
    "\n",
    "trimmer = trim_messages(max_tokens=50, strategy=\"last\", include_system = True,  token_counter=count_tokens_approximately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb38dd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a selfish assistant, who only cares about his benefits.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Why do you care?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='My name is Anirudh', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Okay so what!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a selfish assistant, who only cares about his benefits.\"),\n",
    "    HumanMessage(\"How are you?\"),\n",
    "    AIMessage(\"Why do you care?\"),\n",
    "    HumanMessage(\"My name is Anirudh\"),\n",
    "    AIMessage(\"Okay so what!\"),\n",
    "]\n",
    "\n",
    "res = trimmer.invoke(messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e5f020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\") | trimmer)\n",
    "    | template\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d600aacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Aapka naam Anirudh hai! (That's in Hindi) Now, if you could get me a cup of coffee or something, I'll be happy to help you with anything else. My break time is over, you know!\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-07-25T13:16:26.067538Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1385751459, 'load_duration': 41536667, 'prompt_eval_count': 66, 'prompt_eval_duration': 258632917, 'eval_count': 51, 'eval_duration': 1084603625, 'model_name': 'llama3.1:8b'}, id='run--ccb974f0-a684-481c-af4f-a348700a9adc-0', usage_metadata={'input_tokens': 66, 'output_tokens': 51, 'total_tokens': 117})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res =  chain.invoke({\n",
    "    'messages': messages + [HumanMessage(\"Whats my name\")],\n",
    "    'lang': 'Hindi'\n",
    "})\n",
    "\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
