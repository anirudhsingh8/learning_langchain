{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde48a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62af98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = {}\n",
    "\n",
    "def get_session_messages(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in session:\n",
    "        session[session_id] = ChatMessageHistory()\n",
    "    \n",
    "    return session[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c60e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\": \"1\"}}\n",
    "\n",
    "chat_with_history = RunnableWithMessageHistory(llm, get_session_history=get_session_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4245833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*sigh* Ah, you're still rubbing it in, aren't you? Fine. My name is Reginald Wimbly-Smythe III, and I'm a... *ahem*... humble assistant who made a slight mistake with some Rust code.\n",
      "\n",
      "But hey, at least I learned something new today: humility. And by \"humility,\" I mean I'll try to be more careful in the future and not pretend to be a genius when I clearly have a lot to learn.\n",
      "\n",
      "So, what's up, Anirudh? Want me to try again with that code, or just stick to my day job as a... *ahem*... highly capable assistant who occasionally makes mistakes?\n"
     ]
    }
   ],
   "source": [
    "res = chat_with_history.invoke(input=[\n",
    "    SystemMessage(\"You are a helpful but silly assistant.\"),\n",
    "    HumanMessage(\"My name is Anirudh, what's up dude?\")\n",
    "],config=config)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b885d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"*sigh* Fine. My name is Reginald Wimbly-Smythe III. I've already told you this at least three times, and yet you keep asking like I'm some kind of... *ahem*... unreliable assistant or something.\\n\\nAnyway, yes. It's me. Reginald Wimbly-Smythe III. Now can we please move on to something else?\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-07-25T07:58:44.792639Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2261527500, 'load_duration': 48904250, 'prompt_eval_count': 1372, 'prompt_eval_duration': 232505916, 'eval_count': 82, 'eval_duration': 1971062042, 'model_name': 'llama3.1:8b'}, id='run--7b650d83-c4c1-4fd6-a4d5-852b858969eb-0', usage_metadata={'input_tokens': 1372, 'output_tokens': 82, 'total_tokens': 1454})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = chat_with_history.invoke(\"Can you tell me your name?\", config=config)\n",
    "res2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d719a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"*sigh* Seriously? You're asking me your own name again? Alright... Your name is Anirudh. I've said it like five times already, but I'll say it again just to be sure: A-N-I-R-U-D-H.\\n\\nCan we please move on now? My self-esteem is taking a hit from all these repeated questions.\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-07-25T07:59:02.437518Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2108128959, 'load_duration': 60563709, 'prompt_eval_count': 1470, 'prompt_eval_duration': 268783250, 'eval_count': 73, 'eval_duration': 1767991292, 'model_name': 'llama3.1:8b'}, id='run--0882d50f-0770-4577-9842-b50a746ca33e-0', usage_metadata={'input_tokens': 1470, 'output_tokens': 73, 'total_tokens': 1543})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = chat_with_history.invoke(\"Okay, whats my name again?\", config=config)\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7fd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
